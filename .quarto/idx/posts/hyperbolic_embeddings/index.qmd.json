{"title":"Hyperbolic embeddings","markdown":{"yaml":{"title":"Hyperbolic embeddings","author":"Guillaume Kunsch","date":"2024-03-26","categories":["Machine Learning"],"bibliography":"references.bib","link-citations":true,"draft":false},"headingText":"Intro","containsRefs":false,"markdown":"\n\n\nWhen we think of embeddings, we usually think of Euclidean embeddings, because most of the research carried out on embeddings has been done within the framework of Euclidean geometry.\nHowever, Euclidean geometry is only a particular type of geometry where certain axioms are assumed to be true - Euclid's axioms. \nIf the last axiom - which states that given a line a and a point that is not on that line, there exists only one line parallel to the given line that contains the point - is replaced, we can in fact construct different types of geometries with interesting properties.  \n\nIn this article, we'll take a quick look at the different types of geometry without going into details - that will require an article of its own - and see how and when we can use them in machine learning. \n\n# Non-Euclidean Geometry 101\n\n## Different types of geometry\n\nThere are essentially two ways of replacing Euclid's last postulate:\n\n* either you decide to assume that there are an infinite number of lines, in which case you're in hyperbolic geometry\n* or you decide to assume that there are no lines at all, in which case you're in spherical geometry.\n\n![The different types of geometry. Source: [Cuemath](https://www.cuemath.com/geometry/) ](images/geometry_type.png){width=70%}\n\nWhen you think about it, the Earth's surface defines a spherical geometry, so it shouldn't be too difficult to represent visually. However, this is not entirely true, and I encourage you to watch this [video](https://www.youtube.com/watch?v=zQo_S3yNa2w&ab_channel=CodeParade) which goes a little further and is very well illustrated. Note also that local spherical geometry can be approximated by the classical 2D plane of Euclidean geometry, which is of paramount importance in the mathematical study of this geometry. \n\nHyperbolic geometry is more difficult to represent visually. There are different models, all of them being equivalents. When you think of hyperbolic geometry, think of a space that grows exponentially faster than Euclidean geometry. \n\n## Why not stick to Euclidean ? \n\nIf Euclidean space is the embedding space par excellence, why should we be interested in non-Euclidean geometry? \n\nLet's remember that the aim of an embedding method is to organize symbolic objects - e.g. words, entities, concepts - in such a way that their similarity or distance in the embedding space reflects their semantic similarity. Although embedding methods have proved effective in many applications, they suffer from a fundamental limitation: their ability to model complex models is intrinsically limited by the dimensionality of the embedding space. \nAs a result, it has often been the case that a very large number of dimensions - several hundreds or more - are required to model complex relationships correctly in Euclidean geometry.\n\nHowever, it has been studied and theoretically proven that spherical or hyperbolic geometry can be better equipped mathematically to represent certain relationships using lower dimensions. \nFor example, it has been shown that any finite tree can be embedded in a finite hyperbolic space in such a way that distances are preserved approximately [@gromov1987hyperbolic].\nOn the other hand, Bourgain's theorem [@linial1995geometry] shows that Euclidean space does not allow such low distortion for trees, even using an unlimited number of dimensions.\n\n# What about their usefulness in Machine Learning ? \n\n## Hierarchical representation\n\nFrom now on, for the sake of simplicity, we'll focus on hyperbolic geometry. \n\n[@nickel2017poincare] has shown that hyperbolic geometry can be used to account for the hierarchical representation of tree data. \nThey use the Mammal dataset, which contains relationships between entities such as \"Mammal > Ungulate\", which represents that Ungulate is a subclass of Mammal. \nInformally, hyperbolic space can be seen as a continuous version of trees and, as such, is naturally equipped to model hierarchical structures.  \n\n## Which model for hyperbolic geometry ?\n\nAs previously mentioned, there are several models for hyperbolic geometry. \nGenerally speaking, the two most widely used models in machine learning are the Poincaré model and the hyperboloid model. You can transform coordinates from one to the other, although the hyperboloid has one extra dimension, and they are equivalent. \n\n![Projection of the Poincaré ball onto the hyperboloid. Source : [Wikipedia](https://en.wikipedia.org/wiki/Hyperboloid_model)](images/projection.png){width=70%}\n\n\nAlthough [@nickel2018learning]'s work suggests that the hyperboloid is more stable than the Poincaré model, we'll be conducting experiments using the Poincaré model as it's more appropriate for visual results for a blog post. \n\n## Quick experiments \n\nWe will rely on a synthetic tree generated using [NetworkX](https://networkx.org/) with a depth of size 10 and a branching factor of 2. It containq approxiamtely 2,000 nodes. \nIn line with the method of [@nickel2017poincare], we will train our model on the transitive graph closure, i.e. hypernymy.\n\nWe use a contrastive loss function to pairwise cluster hypernymy while rejecting non-neighbors. \nTo assess the quality of the embeddings, we use the mean approximation error (MAP), which indicates how similar the neighborhood of each node in the embedding space is to that of the tree. \n\n::: {#fig-euclidian layout=\"[10,-2,15]\" layout-valign=\"center\"}\n\n![Embeddings](images/embeddings_euclidian.png)\n\n![Metrics](images/metrics_euclidian.png)\n\nResults with Euclidian space\n:::\n\n::: {#fig-hyperbolic layout=\"[10,-2,15]\" layout-valign=\"center\"}\n\n![Embeddings](images/embeddings_hyperbolic.png)\n\n![Metrics](images/metrics_hyperbolic.png)\n\nResults with hyperbolic space\n:::\n\n\nWe can see that the MAP achieved for hyperbolic space is considerably higher than that for Euclidean space. \nIn addition, the tree hierarchy is visible in the hyperbolic geometry. \n\n\n# Conclusion and food for thought\n\nHyperbolic geometry is an excellent tool for embedding tree structures or other graphs that exhibit a hierarchical structure. \nSome work [@gu2018learning] even suggests that they can be composed to achieve embeddings in the product of hyperbolic, spherical and Euclidean spaces!\n\nHowever, using them is no free-lunch and has a few drawbacks:\n\n- Firstly, because they're a different kind of geometry, you can't combine them directly with the classic +, x, ÷ used in Euclidean geometry. You need more complicated formulas to do this. \n- Secondly, they are subject to instabilities (gradient explosion) and require special attention such as burn-in periods or learning rate adjustment.\n- Thirdly, they are probably not designed for all types of hierarchy. In my own experience, they seem to shine with deep trees (depths greater than 15) where Euclidean space begins to be overwhelmed. \n\nIn short, like any technique, there's a trade-off between the accuracy you want to achieve and the technical difficulties and debt if you want to incorporate them into an ML system. \n\nI hope you've enjoyed it! ","srcMarkdownNoYaml":"\n\n# Intro \n\nWhen we think of embeddings, we usually think of Euclidean embeddings, because most of the research carried out on embeddings has been done within the framework of Euclidean geometry.\nHowever, Euclidean geometry is only a particular type of geometry where certain axioms are assumed to be true - Euclid's axioms. \nIf the last axiom - which states that given a line a and a point that is not on that line, there exists only one line parallel to the given line that contains the point - is replaced, we can in fact construct different types of geometries with interesting properties.  \n\nIn this article, we'll take a quick look at the different types of geometry without going into details - that will require an article of its own - and see how and when we can use them in machine learning. \n\n# Non-Euclidean Geometry 101\n\n## Different types of geometry\n\nThere are essentially two ways of replacing Euclid's last postulate:\n\n* either you decide to assume that there are an infinite number of lines, in which case you're in hyperbolic geometry\n* or you decide to assume that there are no lines at all, in which case you're in spherical geometry.\n\n![The different types of geometry. Source: [Cuemath](https://www.cuemath.com/geometry/) ](images/geometry_type.png){width=70%}\n\nWhen you think about it, the Earth's surface defines a spherical geometry, so it shouldn't be too difficult to represent visually. However, this is not entirely true, and I encourage you to watch this [video](https://www.youtube.com/watch?v=zQo_S3yNa2w&ab_channel=CodeParade) which goes a little further and is very well illustrated. Note also that local spherical geometry can be approximated by the classical 2D plane of Euclidean geometry, which is of paramount importance in the mathematical study of this geometry. \n\nHyperbolic geometry is more difficult to represent visually. There are different models, all of them being equivalents. When you think of hyperbolic geometry, think of a space that grows exponentially faster than Euclidean geometry. \n\n## Why not stick to Euclidean ? \n\nIf Euclidean space is the embedding space par excellence, why should we be interested in non-Euclidean geometry? \n\nLet's remember that the aim of an embedding method is to organize symbolic objects - e.g. words, entities, concepts - in such a way that their similarity or distance in the embedding space reflects their semantic similarity. Although embedding methods have proved effective in many applications, they suffer from a fundamental limitation: their ability to model complex models is intrinsically limited by the dimensionality of the embedding space. \nAs a result, it has often been the case that a very large number of dimensions - several hundreds or more - are required to model complex relationships correctly in Euclidean geometry.\n\nHowever, it has been studied and theoretically proven that spherical or hyperbolic geometry can be better equipped mathematically to represent certain relationships using lower dimensions. \nFor example, it has been shown that any finite tree can be embedded in a finite hyperbolic space in such a way that distances are preserved approximately [@gromov1987hyperbolic].\nOn the other hand, Bourgain's theorem [@linial1995geometry] shows that Euclidean space does not allow such low distortion for trees, even using an unlimited number of dimensions.\n\n# What about their usefulness in Machine Learning ? \n\n## Hierarchical representation\n\nFrom now on, for the sake of simplicity, we'll focus on hyperbolic geometry. \n\n[@nickel2017poincare] has shown that hyperbolic geometry can be used to account for the hierarchical representation of tree data. \nThey use the Mammal dataset, which contains relationships between entities such as \"Mammal > Ungulate\", which represents that Ungulate is a subclass of Mammal. \nInformally, hyperbolic space can be seen as a continuous version of trees and, as such, is naturally equipped to model hierarchical structures.  \n\n## Which model for hyperbolic geometry ?\n\nAs previously mentioned, there are several models for hyperbolic geometry. \nGenerally speaking, the two most widely used models in machine learning are the Poincaré model and the hyperboloid model. You can transform coordinates from one to the other, although the hyperboloid has one extra dimension, and they are equivalent. \n\n![Projection of the Poincaré ball onto the hyperboloid. Source : [Wikipedia](https://en.wikipedia.org/wiki/Hyperboloid_model)](images/projection.png){width=70%}\n\n\nAlthough [@nickel2018learning]'s work suggests that the hyperboloid is more stable than the Poincaré model, we'll be conducting experiments using the Poincaré model as it's more appropriate for visual results for a blog post. \n\n## Quick experiments \n\nWe will rely on a synthetic tree generated using [NetworkX](https://networkx.org/) with a depth of size 10 and a branching factor of 2. It containq approxiamtely 2,000 nodes. \nIn line with the method of [@nickel2017poincare], we will train our model on the transitive graph closure, i.e. hypernymy.\n\nWe use a contrastive loss function to pairwise cluster hypernymy while rejecting non-neighbors. \nTo assess the quality of the embeddings, we use the mean approximation error (MAP), which indicates how similar the neighborhood of each node in the embedding space is to that of the tree. \n\n::: {#fig-euclidian layout=\"[10,-2,15]\" layout-valign=\"center\"}\n\n![Embeddings](images/embeddings_euclidian.png)\n\n![Metrics](images/metrics_euclidian.png)\n\nResults with Euclidian space\n:::\n\n::: {#fig-hyperbolic layout=\"[10,-2,15]\" layout-valign=\"center\"}\n\n![Embeddings](images/embeddings_hyperbolic.png)\n\n![Metrics](images/metrics_hyperbolic.png)\n\nResults with hyperbolic space\n:::\n\n\nWe can see that the MAP achieved for hyperbolic space is considerably higher than that for Euclidean space. \nIn addition, the tree hierarchy is visible in the hyperbolic geometry. \n\n\n# Conclusion and food for thought\n\nHyperbolic geometry is an excellent tool for embedding tree structures or other graphs that exhibit a hierarchical structure. \nSome work [@gu2018learning] even suggests that they can be composed to achieve embeddings in the product of hyperbolic, spherical and Euclidean spaces!\n\nHowever, using them is no free-lunch and has a few drawbacks:\n\n- Firstly, because they're a different kind of geometry, you can't combine them directly with the classic +, x, ÷ used in Euclidean geometry. You need more complicated formulas to do this. \n- Secondly, they are subject to instabilities (gradient explosion) and require special attention such as burn-in periods or learning rate adjustment.\n- Thirdly, they are probably not designed for all types of hierarchy. In my own experience, they seem to shine with deep trees (depths greater than 15) where Euclidean space begins to be overwhelmed. \n\nIn short, like any technique, there's a trade-off between the accuracy you want to achieve and the technical difficulties and debt if you want to incorporate them into an ML system. \n\nI hope you've enjoyed it! "},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":true,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"markdown"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../../styles.css"],"toc":true,"toc-depth":3,"output-file":"index.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.4.549","comments":{"utterances":{"repo":"blog","theme":"github-light"}},"page-layout":"article","theme":"flatly","toc-title":"**Sections**","title-block-banner":true,"sidebar":"articles","author":"Guillaume Kunsch","title":"Hyperbolic embeddings","date":"2024-03-26","categories":["Machine Learning"],"bibliography":["references.bib"],"link-citations":true,"draft":false},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}